{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LayoutNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SwastiKh/LayoutNet/blob/main/LayoutNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIznuvJhbNYO",
        "outputId": "2fb2414a-cb20-4d06-8ff3-ac6c18cc44e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "!git clone https://github.com/SwastiKh/LayoutNet.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'LayoutNet'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 12 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (12/12), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_bTZLzC--Cs",
        "outputId": "c94a2858-6ee5-45c4-d8c6-7bef6e93ef81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "!apt-get install 2to3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  2to3\n",
            "0 upgraded, 1 newly installed, 0 to remove and 6 not upgraded.\n",
            "Need to get 8,044 B of archives.\n",
            "After this operation, 43.0 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 2to3 all 3.6.7-1~18.04 [8,044 B]\n",
            "Fetched 8,044 B in 0s (28.8 kB/s)\n",
            "Selecting previously unselected package 2to3.\n",
            "(Reading database ... 144617 files and directories currently installed.)\n",
            "Preparing to unpack .../2to3_3.6.7-1~18.04_all.deb ...\n",
            "Unpacking 2to3 (3.6.7-1~18.04) ...\n",
            "Setting up 2to3 (3.6.7-1~18.04) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9-iQ4XKCqXh",
        "outputId": "dcd5812e-b6eb-452d-ffd5-2f19c7109815",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd LayoutNet/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/LayoutNet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSpeXGjUCF3i"
      },
      "source": [
        "!2to3 . -w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drKkNS46DV5M",
        "outputId": "27e24472-2dea-4f5e-ff39-211efe0e8a24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBTjShMLDXD8"
      },
      "source": [
        "!git add ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58o7z_o0Gavj",
        "outputId": "8ae82c78-60cf-4235-e37a-827137a6871e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "!git commit -m \"Changed the code from python 2 to 3\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[main 3303e56] Changed the code from python 2 to 3\n",
            " 4 files changed, 359 insertions(+), 5 deletions(-)\n",
            " create mode 100644 test.py.bak\n",
            " create mode 100644 trainer_step.py.bak\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib59rdrqGjm8"
      },
      "source": [
        "!git config --global user.email \"anjul.ten@gmail.com\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd6f--axGoh4"
      },
      "source": [
        "!git config --global user.name \"tyagi-iiitv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFZZoPQWGrlI",
        "outputId": "6aa4b30b-8df8-4151-c610-276b323a11a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY08thw2Gu3k",
        "outputId": "439c2fdc-0114-4362-9edd-b0004a83b61b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "!git clone https://github.com/SwastiKh/LayoutNet.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'LayoutNet'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 24 (delta 10), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (24/24), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H97s2S7VHhlv"
      },
      "source": [
        "!cd LayoutNet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjeNb6eSHNrP",
        "outputId": "fb95ac1b-5e10-429f-a7fb-ce650028c082",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!python train.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file 'train.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9Wx2b1FHpcE",
        "outputId": "efe9808d-d2d1-4c15-e4ab-774f554725f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LayoutNet  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tfq_u_U6HxjO",
        "outputId": "8c642abd-6466-4fb1-fce8-420963b0af9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd LayoutNet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/LayoutNet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BZQ_h9KH_n2",
        "outputId": "62b71ce7-9f19-47ec-cd24-7e3715461063",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "!python train.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-13 08:42:40.507054: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 2, in <module>\n",
            "    import trainer_step\n",
            "  File \"/content/LayoutNet/trainer_step.py\", line 8, in <module>\n",
            "    import model\n",
            "  File \"/content/LayoutNet/model.py\", line 2, in <module>\n",
            "    slim = tf.contrib.slim\n",
            "AttributeError: module 'tensorflow' has no attribute 'contrib'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CJsLPNTICtj",
        "outputId": "e90f397a-ebe6-47c6-953e-2c8895ebcdc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "tf_upgrade_v2 \\\n",
        "  --intree LayoutNet/ \\\n",
        "  --outtree LayoutNet_upgraded/ \\\n",
        "  --reportfile report.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-f9499a69d20b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    tf_upgrade_v2   --intree LayoutNet/   --outtree LayoutNet_upgraded/   --reportfile report.txt\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV5F53kmlTUw",
        "outputId": "158dde1e-6301-4961-9fe9-b201dbbe9d14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pip install tf-nightly-2.0-preview / tf-nightly-gpu-2.0-preview"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Directory '/' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLy8uvrimluA",
        "outputId": "27a40d7d-2562-45d9-e6db-858b995612ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "!git clone https://github.com/SwastiKh/LayoutNet.git\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'LayoutNet'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 24 (delta 10), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (24/24), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szKMQ6MynF7e",
        "outputId": "f471a315-27d7-49a4-e92a-f14fac3cc317",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "pip install tf-nightly-gpu-2.0-preview"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tf-nightly-gpu-2.0-preview (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for tf-nightly-gpu-2.0-preview\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcnkYtXZ39-_",
        "outputId": "efb81efc-0724-4a1f-d711-51a7847d1c1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eVEw0Vd_tWw",
        "outputId": "0a567c19-b15d-4104-83b6-49944ffeb7ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        }
      },
      "source": [
        "!tf_upgrade_v2 -h"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: tf_upgrade_v2 [-h] [--infile INPUT_FILE] [--outfile OUTPUT_FILE]\n",
            "                     [--intree INPUT_TREE] [--outtree OUTPUT_TREE]\n",
            "                     [--copyotherfiles COPY_OTHER_FILES] [--inplace]\n",
            "                     [--import_rename] [--reportfile REPORT_FILENAME]\n",
            "                     [--mode {DEFAULT,SAFETY}] [--print_all]\n",
            "\n",
            "Convert a TensorFlow Python file from 1.x to 2.0\n",
            "\n",
            "Simple usage:\n",
            "  tf_upgrade_v2.py --infile foo.py --outfile bar.py\n",
            "  tf_upgrade_v2.py --infile foo.ipynb --outfile bar.ipynb\n",
            "  tf_upgrade_v2.py --intree ~/code/old --outtree ~/code/new\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --infile INPUT_FILE   If converting a single file, the name of the file to\n",
            "                        convert\n",
            "  --outfile OUTPUT_FILE\n",
            "                        If converting a single file, the output filename.\n",
            "  --intree INPUT_TREE   If converting a whole tree of files, the directory to\n",
            "                        read from (relative or absolute).\n",
            "  --outtree OUTPUT_TREE\n",
            "                        If converting a whole tree of files, the output\n",
            "                        directory (relative or absolute).\n",
            "  --copyotherfiles COPY_OTHER_FILES\n",
            "                        If converting a whole tree of files, whether to copy\n",
            "                        the other files.\n",
            "  --inplace             If converting a set of files, whether to allow the\n",
            "                        conversion to be performed on the input files.\n",
            "  --import_rename       Whether to rename import to compact.v2 explicitly.\n",
            "  --reportfile REPORT_FILENAME\n",
            "                        The name of the file where the report log is\n",
            "                        stored.(default: report.txt)\n",
            "  --mode {DEFAULT,SAFETY}\n",
            "                        Upgrade script mode. Supported modes: DEFAULT: Perform\n",
            "                        only straightforward conversions to upgrade to 2.0. In\n",
            "                        more difficult cases, switch to use compat.v1. SAFETY:\n",
            "                        Keep 1.* code intact and import compat.v1 module.\n",
            "  --print_all           Print full log to stdout instead of just printing\n",
            "                        errors\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpylpEqdlKOr",
        "outputId": "a7bf2e2c-ff39-430d-85af-2b697f0e0dc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!tf_upgrade_v2 \\\n",
        "  --intree LayoutNet \\\n",
        "  --outtree LayoutNet_upgraded \\\n",
        "  --reportfile report.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR line 10:7: Using member tf.contrib.slim in deprecated module tf.contrib. tf.contrib.slim cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.\n",
            "INFO line 15:24: Renamed 'tf.train.string_input_producer' to 'tf.compat.v1.train.string_input_producer'\n",
            "INFO line 18:21: Renamed 'tf.train.Saver' to 'tf.compat.v1.train.Saver'\n",
            "INFO line 23:30: tf.summary.merge requires manual check. The TF 1.x summary API cannot be automatically migrated to TF 2.0, so symbols have been converted to tf.compat.v1.summary.* and must be migrated manually. Typical usage will only require changes to the summary writing logic, not to individual calls like scalar(). For examples of the new summary API, see the Effective TF 2.0 migration document or check the TF 2.0 TensorBoard tutorials.\n",
            "INFO line 23:30: Renamed 'tf.summary.merge' to 'tf.compat.v1.summary.merge'\n",
            "INFO line 24:12: tf.summary.scalar requires manual check. The TF 1.x summary API cannot be automatically migrated to TF 2.0, so symbols have been converted to tf.compat.v1.summary.* and must be migrated manually. Typical usage will only require changes to the summary writing logic, not to individual calls like scalar(). For examples of the new summary API, see the Effective TF 2.0 migration document or check the TF 2.0 TensorBoard tutorials.\n",
            "INFO line 24:12: Renamed 'tf.summary.scalar' to 'tf.compat.v1.summary.scalar'\n",
            "INFO line 25:12: tf.summary.scalar requires manual check. The TF 1.x summary API cannot be automatically migrated to TF 2.0, so symbols have been converted to tf.compat.v1.summary.* and must be migrated manually. Typical usage will only require changes to the summary writing logic, not to individual calls like scalar(). For examples of the new summary API, see the Effective TF 2.0 migration document or check the TF 2.0 TensorBoard tutorials.\n",
            "INFO line 25:12: Renamed 'tf.summary.scalar' to 'tf.compat.v1.summary.scalar'\n",
            "INFO line 26:12: tf.summary.scalar requires manual check. The TF 1.x summary API cannot be automatically migrated to TF 2.0, so symbols have been converted to tf.compat.v1.summary.* and must be migrated manually. Typical usage will only require changes to the summary writing logic, not to individual calls like scalar(). For examples of the new summary API, see the Effective TF 2.0 migration document or check the TF 2.0 TensorBoard tutorials.\n",
            "INFO line 26:12: Renamed 'tf.summary.scalar' to 'tf.compat.v1.summary.scalar'\n",
            "INFO line 27:12: tf.summary.scalar requires manual check. The TF 1.x summary API cannot be automatically migrated to TF 2.0, so symbols have been converted to tf.compat.v1.summary.* and must be migrated manually. Typical usage will only require changes to the summary writing logic, not to individual calls like scalar(). For examples of the new summary API, see the Effective TF 2.0 migration document or check the TF 2.0 TensorBoard tutorials.\n",
            "INFO line 27:12: Renamed 'tf.summary.scalar' to 'tf.compat.v1.summary.scalar'\n",
            "INFO line 28:12: tf.summary.scalar requires manual check. The TF 1.x summary API cannot be automatically migrated to TF 2.0, so symbols have been converted to tf.compat.v1.summary.* and must be migrated manually. Typical usage will only require changes to the summary writing logic, not to individual calls like scalar(). For examples of the new summary API, see the Effective TF 2.0 migration document or check the TF 2.0 TensorBoard tutorials.\n",
            "INFO line 28:12: Renamed 'tf.summary.scalar' to 'tf.compat.v1.summary.scalar'\n",
            "INFO line 29:30: tf.summary.FileWriter requires manual check. The TF 1.x summary API cannot be automatically migrated to TF 2.0, so symbols have been converted to tf.compat.v1.summary.* and must be migrated manually. Typical usage will only require changes to the summary writing logic, not to individual calls like scalar(). For examples of the new summary API, see the Effective TF 2.0 migration document or check the TF 2.0 TensorBoard tutorials.\n",
            "INFO line 29:30: Renamed 'tf.summary.FileWriter' to 'tf.compat.v1.summary.FileWriter'\n",
            "INFO line 31:22: Renamed 'tf.ConfigProto' to 'tf.compat.v1.ConfigProto'\n",
            "INFO line 33:24: Renamed 'tf.GPUOptions' to 'tf.compat.v1.GPUOptions'\n",
            "INFO line 34:20: Renamed 'tf.Session' to 'tf.compat.v1.Session'\n",
            "INFO line 40:13: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 41:20: Renamed 'tf.placeholder' to 'tf.compat.v1.placeholder'\n",
            "INFO line 56:18: Renamed 'tf.random_normal' to 'tf.random.normal'\n",
            "INFO line 84:13: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "INFO line 85:28: Added keywords to args of function 'tf.reduce_sum'\n",
            "INFO line 94:25: Added keywords to args of function 'tf.reduce_sum'\n",
            "INFO line 96:21: Added keywords to args of function 'tf.reduce_mean'\n",
            "INFO line 98:13: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "INFO line 99:26: Added keywords to args of function 'tf.reduce_mean'\n",
            "INFO line 100:26: Added keywords to args of function 'tf.reduce_mean'\n",
            "INFO line 103:13: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "INFO line 104:23: Added keywords to args of function 'tf.reduce_mean'\n",
            "INFO line 106:28: Added keywords to args of function 'tf.reduce_sum'\n",
            "INFO line 115:25: Added keywords to args of function 'tf.reduce_sum'\n",
            "INFO line 117:22: Added keywords to args of function 'tf.reduce_mean'\n",
            "INFO line 119:25: Added keywords to args of function 'tf.reduce_mean'\n",
            "INFO line 122:13: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "INFO line 123:37: Renamed 'tf.trainable_variables' to 'tf.compat.v1.trainable_variables'\n",
            "INFO line 125:20: Renamed 'tf.train.AdamOptimizer' to 'tf.compat.v1.train.AdamOptimizer'\n",
            "INFO line 130:13: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "INFO line 131:37: Renamed 'tf.trainable_variables' to 'tf.compat.v1.trainable_variables'\n",
            "INFO line 133:20: Renamed 'tf.train.AdamOptimizer' to 'tf.compat.v1.train.AdamOptimizer'\n",
            "INFO line 137:13: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "INFO line 138:37: Renamed 'tf.trainable_variables' to 'tf.compat.v1.trainable_variables'\n",
            "INFO line 140:20: Renamed 'tf.train.AdamOptimizer' to 'tf.compat.v1.train.AdamOptimizer'\n",
            "INFO line 158:22: Renamed 'tf.global_variables_initializer' to 'tf.compat.v1.global_variables_initializer'\n",
            "INFO line 160:18: Renamed 'tf.train.start_queue_runners' to 'tf.compat.v1.train.start_queue_runners'\n",
            "WARNING line 199:16: *.save requires manual check. (This warning is only applicable if the code saves a tf.Keras model) Keras model.save now saves to the Tensorflow SavedModel format by default, instead of HDF5. To continue saving to HDF5, add the argument save_format='h5' to the save() function.\n",
            "INFO line 224:20: Renamed 'tf.train.import_meta_graph' to 'tf.compat.v1.train.import_meta_graph'\n",
            "INFO line 288:17: Renamed 'tf.TFRecordReader' to 'tf.compat.v1.TFRecordReader'\n",
            "INFO line 290:19: Added keywords to args of function 'tf.parse_single_example'\n",
            "INFO line 290:19: Renamed 'tf.parse_single_example' to 'tf.io.parse_single_example'\n",
            "INFO line 293:25: Renamed 'tf.FixedLenFeature' to 'tf.io.FixedLenFeature'\n",
            "INFO line 294:29: Renamed 'tf.FixedLenFeature' to 'tf.io.FixedLenFeature'\n",
            "INFO line 295:28: Renamed 'tf.FixedLenFeature' to 'tf.io.FixedLenFeature'\n",
            "INFO line 296:29: Renamed 'tf.FixedLenFeature' to 'tf.io.FixedLenFeature'\n",
            "INFO line 297:30: Renamed 'tf.FixedLenFeature' to 'tf.io.FixedLenFeature'\n",
            "INFO line 298:27: Renamed 'tf.FixedLenFeature' to 'tf.io.FixedLenFeature'\n",
            "INFO line 301:36: Renamed 'tf.decode_raw' to 'tf.io.decode_raw'\n",
            "INFO line 304:24: Renamed 'tf.image.resize_image_with_crop_or_pad' to 'tf.image.resize_with_crop_or_pad'\n",
            "INFO line 310:20: Renamed 'tf.decode_raw' to 'tf.io.decode_raw'\n",
            "INFO line 313:21: Renamed 'tf.decode_raw' to 'tf.io.decode_raw'\n",
            "INFO line 316:71: Renamed 'tf.train.shuffle_batch' to 'tf.compat.v1.train.shuffle_batch'\n",
            "ERROR line 2:7: Using member tf.contrib.slim in deprecated module tf.contrib. tf.contrib.slim cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.\n",
            "INFO line 16:9: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "INFO line 24:44: tf.truncated_normal_initializer requires manual check. Initializers no longer have the dtype argument in the constructor or partition_info argument in the __call__ method.\n",
            "The calls have been converted to compat.v1 for safety (even though they may already have been correct).\n",
            "INFO line 24:44: Renamed 'tf.truncated_normal_initializer' to 'tf.compat.v1.truncated_normal_initializer'\n",
            "INFO line 33:9: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "INFO line 62:44: tf.truncated_normal_initializer requires manual check. Initializers no longer have the dtype argument in the constructor or partition_info argument in the __call__ method.\n",
            "The calls have been converted to compat.v1 for safety (even though they may already have been correct).\n",
            "INFO line 62:44: Renamed 'tf.truncated_normal_initializer' to 'tf.compat.v1.truncated_normal_initializer'\n",
            "INFO line 71:9: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "INFO line 74:21: Added keywords to args of function 'tf.reduce_mean'\n",
            "INFO line 93:44: tf.truncated_normal_initializer requires manual check. Initializers no longer have the dtype argument in the constructor or partition_info argument in the __call__ method.\n",
            "The calls have been converted to compat.v1 for safety (even though they may already have been correct).\n",
            "INFO line 93:44: Renamed 'tf.truncated_normal_initializer' to 'tf.compat.v1.truncated_normal_initializer'\n",
            "INFO line 102:9: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "INFO line 123:44: tf.truncated_normal_initializer requires manual check. Initializers no longer have the dtype argument in the constructor or partition_info argument in the __call__ method.\n",
            "The calls have been converted to compat.v1 for safety (even though they may already have been correct).\n",
            "INFO line 123:44: Renamed 'tf.truncated_normal_initializer' to 'tf.compat.v1.truncated_normal_initializer'\n",
            "INFO line 132:9: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "INFO line 150:44: tf.truncated_normal_initializer requires manual check. Initializers no longer have the dtype argument in the constructor or partition_info argument in the __call__ method.\n",
            "The calls have been converted to compat.v1 for safety (even though they may already have been correct).\n",
            "INFO line 150:44: Renamed 'tf.truncated_normal_initializer' to 'tf.compat.v1.truncated_normal_initializer'\n",
            "INFO line 167:9: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "INFO line 192:44: tf.truncated_normal_initializer requires manual check. Initializers no longer have the dtype argument in the constructor or partition_info argument in the __call__ method.\n",
            "The calls have been converted to compat.v1 for safety (even though they may already have been correct).\n",
            "INFO line 192:44: Renamed 'tf.truncated_normal_initializer' to 'tf.compat.v1.truncated_normal_initializer'\n",
            "INFO line 209:9: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "INFO line 241:44: tf.truncated_normal_initializer requires manual check. Initializers no longer have the dtype argument in the constructor or partition_info argument in the __call__ method.\n",
            "The calls have been converted to compat.v1 for safety (even though they may already have been correct).\n",
            "INFO line 241:44: Renamed 'tf.truncated_normal_initializer' to 'tf.compat.v1.truncated_normal_initializer'\n",
            "INFO line 253:9: Renamed 'tf.variable_scope' to 'tf.compat.v1.variable_scope'\n",
            "TensorFlow 2.0 Upgrade Script\n",
            "-----------------------------\n",
            "Converted 5 files\n",
            "Detected 3 issues that require attention\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "File: LayoutNet/model.py\n",
            "--------------------------------------------------------------------------------\n",
            "LayoutNet/model.py:2:7: ERROR: Using member tf.contrib.slim in deprecated module tf.contrib. tf.contrib.slim cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.\n",
            "--------------------------------------------------------------------------------\n",
            "File: LayoutNet/trainer_step.py\n",
            "--------------------------------------------------------------------------------\n",
            "LayoutNet/trainer_step.py:10:7: ERROR: Using member tf.contrib.slim in deprecated module tf.contrib. tf.contrib.slim cannot be converted automatically. tf.contrib will not be distributed with TensorFlow 2.0, please consider an alternative in non-contrib TensorFlow, a community-maintained repository such as tensorflow/addons, or fork the required code.\n",
            "LayoutNet/trainer_step.py:199:16: WARNING: *.save requires manual check. (This warning is only applicable if the code saves a tf.Keras model) Keras model.save now saves to the Tensorflow SavedModel format by default, instead of HDF5. To continue saving to HDF5, add the argument save_format='h5' to the save() function.\n",
            "\n",
            "\n",
            "Make sure to read the detailed log 'report.txt'\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dAyu-xmA3zx",
        "outputId": "328f5723-878c-428f-bb2c-ef7998f54351",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd content/LayoutNet_upgraded/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/LayoutNet_upgraded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKoZH8xLA78L",
        "outputId": "30f80642-efbb-41e0-d7c2-5ab966d8764d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "!python train.py\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-13 12:51:47.995963: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 2, in <module>\n",
            "    import trainer_step\n",
            "  File \"/content/LayoutNet_upgraded/trainer_step.py\", line 8, in <module>\n",
            "    import model\n",
            "  File \"/content/LayoutNet_upgraded/model.py\", line 2, in <module>\n",
            "    slim = tf.contrib.slim\n",
            "AttributeError: module 'tensorflow' has no attribute 'contrib'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aYktn6uBEGI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}